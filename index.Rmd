---
title: "Aplicación del modelo lineal general"
author: "Vásquez V., C.R.A."
date: "`r Sys.Date()`"
subtitle: Recuento de escarabajos en un área
institute: InkaStats - Data Science Solutions S.A.C.
site: bookdown::bookdown_site
---

```{=html}
<style>
body {
text-align: justify}
</style>
```
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
options(max.print = 9999,
        scipen = 999)
```

# Reconocimiento de variables

Para crear un modelo de regresión lineal se tomó como variable dependiente al *Recuento de escarabajos en un área*. Las posibles variables predictoras fueron:

*Temperatura*: Temperatura (°C) ambiental.

*Altura*: Altura (msnsm) del ambiente.

*Humedad*: Humedad relativa (%) ambiental.

*Machos*: Genero predominante en el área (0 si predominan machos, 1 si hembras).

*Urbano*: 0 (No) si el conteo se hizo en un área no urbana, 1 (Sí) si el conteo se hizo en un área urbana.

# Análisis exploratorio y descriptivo

## Análisis descriptivo

Los datos cuenta con un total de 200 observaciones (n=200).

\changefontsizes{6pt}

```{r, echo = F, eval=T, comment="", message=F, warning= F}
datos <- readxl::read_xlsx("datos11.xlsx", sheet = "Sheet1")
datos$Macho <- factor(datos$Macho,
                      levels = c(0,1),
                      labels = c("Machos","Hembras"))
datos$Urbano <- factor(datos$Urbano,
                      levels = c(0,1),
                      labels = c("No","Sí"))

library(summarytools)
summarytools::descr(datos)
```

\changefontsizes{7pt}

```{r, echo = F, eval=T, comment="", message=F, warning= F}
summary(datos)
```

## Gráficos exploratorios

```{r, echo = F, eval=T, message=F, comment="", warning= F, fig.align='center'}
library(dplyr)
datos %>%
    select_if(is.numeric) %>%
    pairs
```

```{r, echo = F, eval=T, message=F, comment="", warning= F, fig.align='center'}
library(psych)
datos %>%
    select_if(is.numeric) %>%
    pairs.panels
```

```{r, echo = F, eval=T, message=F, comment="", warning= F, fig.align='center'}
library(ggplot2)
library(GGally)
datos %>%
    ggpairs + theme_bw()
```

```{r, echo = F, eval=T, message=F, comment="", warning= F, fig.align='center'}
library(ggplot2)
library(GGally)
datos %>%
    ggpairs(upper = list(continuous = "density", combo = "box_no_facet"), lower = list(continuous = "points", 
        combo = "dot_no_facet")) + theme_bw()
```

```{r, echo = F, eval=T, message=F, comment="", warning= F, fig.align='center'}
#Generando gráfico de dispersión del número de bayas cosechables vs los Kg Cosechados por hectárea
library(ggplot2)
datos %>% 
  ggplot(aes(x=Altura,y=Recuento))+
  geom_point(position = "jitter", size=3, colour="red")+
  labs( title = "DIAGRAMA DE DISPERSIÓN",
        subtitle = "Altura vs Recuento")+
  geom_smooth(method = "lm")+
  theme_test()
```

# Modelo de regresión lineal multiple completo

## Resumen del modelo

A continuación presentamos el modelo completo:

$$Recuento=\beta_0+\beta_1*Temperatura+\beta_2*Altura+\beta_3*Humedad+\beta_4*Hembras+\beta_5*Urbano+\epsilon_i$$

\changefontsizes{5pt}

```{r, echo = F, eval=T, message=F, warning= F, comment=""}
lm(Recuento~.,datos) -> modelo_completo
summary(modelo_completo)
```

## Análisis de variancia

```{r, echo = F, eval=T, message=F, warning= F, comment=""}
anova(modelo_completo)
```

# Selección de variables paso a paso

## Partición inicial de la base de datos

### Resumen de la base de datos de entrenamiento

\changefontsizes{6pt}

```{r, echo = F, eval=T, message=F, warning= F, comment=""}
library(caret)
set.seed(6666)
train <- createDataPartition(y = datos$Recuento, p = 0.80, list = FALSE, times = 1)
datos.train <- datos[train, ]
datos.test  <- datos[-train, ]
# summarytools::descr(datos.train)
summary(datos.train)
```

### Resumen de la base de datos de prueba

\changefontsizes{6pt}

```{r, echo = F, eval=T, message=F, warning= F, comment=""}
# summarytools::descr(datos.test)
summary(datos.test)
```

### Verificación de la distribución de la variable respuesta (Recuento)

```{r, echo = F, eval=T, message=F, comment="", warning= F, fig.align='center'}
par(mfrow = c(1,3))
hist(datos$Recuento,
                           main = "Datos completos",
                           sub = c("Media = 196.925"),
     xlab = "Recuento")
hist(datos.train$Recuento,
                           main = "Datos de entrenamiento",
                           sub = c("Media = 196.7267"),
     xlab = "Recuento")
hist(datos.test$Recuento,
                           main = "Datos de prueba",
                           sub = c("Media = 197.7436"),
     xlab = "Recuento")
```

## Forward

### Resumen del modelo

\changefontsizes{5pt}

```{r, echo = F, eval=T, message=F, comment="", warning= F, fig.align='center'}
step(object = lm(formula = Recuento ~ 1, data = datos.train),
 direction = "forward",
 scope = formula(lm(Recuento~.,data=datos)),
 trace = F) -> modelo_forward
modelo_forward %>% summary
```

### AIC del modelo

```{r, echo = F, eval=T, message=F, comment="", warning= F, fig.align='center'}
AIC(modelo_forward)
```

### Coeficientes del modelo

\changefontsizes{5pt}

```{r, echo = F, eval=T, message=F, comment="", warning= F, fig.align='center'}
library(tidyverse)
library(broom)
modelo_forward %>% 
 tidy %>% 
 filter(term != "(Intercept)") %>% 
 ggplot(aes(x = term, y = estimate)) +
 geom_col() +
 labs(title = "Coeficientes del modelo OLS") +
 theme_bw() +
 theme(axis.text.x = element_text(size = 8, angle = 90))
```

### VIF de las variables seleccionadas

```{r, echo = F, eval=T, message=F, comment="", warning= F, fig.align='center'}
library(faraway)
modelo_forward %>% vif
```

### MSE del entrenamiento

```{r, echo = F, eval=T, message=F, comment="", warning= F, fig.align='center'}
modelo_forward %>% predict(newdata = data.frame(datos.train)) -> predicciones_train
(mean((predicciones_train - datos.train$Recuento)^2) -> training_mse)
```

### Indicadores predictivos con la base de datos de entrenamiento

```{r, echo = F, eval=T, message=F, comment="", warning= F, fig.align='center'}
library(caret)
postResample(predicciones_train, obs = datos.train$Recuento)
```

## Backward

### Resumen del modelo

\changefontsizes{5pt}

```{r, echo = F, eval=T, message=F, comment="", warning= F, fig.align='center'}
step(object = lm(formula = Recuento ~ ., data = datos.train),
 direction = "backward",
 scope = list(upper = ~., lower = ~1),
 trace = F) -> modelo_backward
modelo_backward %>% summary
```

### AIC del modelo

```{r, echo = F, eval=T, message=F, comment="", warning= F, fig.align='center'}
AIC(modelo_backward)
```

### Coeficientes del modelo

\changefontsizes{5pt}

```{r, echo = F, eval=T, message=F, comment="", warning= F, fig.align='center'}
library(tidyverse)
library(broom)
modelo_backward %>% 
 tidy %>% 
 filter(term != "(Intercept)") %>% 
 ggplot(aes(x = term, y = estimate)) +
 geom_col() +
 labs(title = "Coeficientes del modelo OLS") +
 theme_bw() +
 theme(axis.text.x = element_text(size = 8, angle = 90))
```

### VIF de las variables seleccionadas

```{r, echo = F, eval=T, message=F, comment="", warning= F, fig.align='center'}
library(faraway)
modelo_backward %>% vif
```

### MSE del entrenamiento

```{r, echo = F, eval=T, message=F, comment="", warning= F, fig.align='center'}
modelo_backward %>% predict(newdata = data.frame(datos.train)) -> predicciones_train
(mean((predicciones_train - datos.train$Recuento)^2) -> training_mse)
```

### Indicadores predictivos con la base de datos de entrenamiento

```{r, echo = F, eval=T, message=F, comment="", warning= F, fig.align='center'}
library(caret)
postResample(predicciones_train, obs = datos.train$Recuento)
```

## Stepwise

### Resumen del modelo

\changefontsizes{5pt}

```{r, echo = F, eval=T, message=F, comment="", warning= F, fig.align='center'}
step(object = lm(formula = Recuento ~ 1, data = datos.train),
 direction = "both",
 scope = formula(lm(Recuento~.,data=datos)),
 trace = F,
 k = log(nrow(datos.train))) -> modelo_step
modelo_step %>% summary
```

### AIC del modelo

```{r, echo = F, eval=T, message=F, comment="", warning= F, fig.align='center'}
AIC(modelo_step)
```

### Coeficientes del modelo

\changefontsizes{5pt}

```{r, echo = F, eval=T, message=F, comment="", warning= F, fig.align='center'}
library(tidyverse)
library(broom)
modelo_step %>% 
 tidy %>% 
 filter(term != "(Intercept)") %>% 
 ggplot(aes(x = term, y = estimate)) +
 geom_col() +
 labs(title = "Coeficientes del modelo OLS") +
 theme_bw() +
 theme(axis.text.x = element_text(size = 8, angle = 90))
```

### VIF de las variables seleccionadas

```{r, echo = F, eval=T, message=F, comment="", warning= F, fig.align='center'}
library(faraway)
modelo_step %>% vif
```

### MSE del entrenamiento

```{r, echo = F, eval=T, message=F, comment="", warning= F, fig.align='center'}
modelo_step %>% predict(newdata = data.frame(datos.train)) -> predicciones_train
(mean((predicciones_train - datos.train$Recuento)^2) -> training_mse)
```

### Indicadores predictivos con la base de datos de entrenamiento

```{r, echo = F, eval=T, message=F, comment="", warning= F, fig.align='center'}
library(caret)
postResample(predicciones_train, obs = datos.train$Recuento)
```

## Comparación de modelos

\changefontsizes{7pt}

|            |          |                    |           |           |           |
|------------|----------|--------------------|-----------|-----------|-----------|
| *Método*   | $AIC$    | $R^2$ **ajustado** | $RMSE$    | $R^2$     | $MAE$     |
| *Forward*  | 973.239  | 99.54              | 4.8186162 | 0.9955231 | 3.7545822 |
| *Backward* | 973.239  | 99.54              | 4.8186162 | 0.9955231 | 3.7545822 |
| *Stepwise* | 976.0164 | 99.53              | 4.8906414 | 0.9953883 | 3.8580781 |

Se selecciona al modelo Stepwise, por lo que el modelo final considerará a las variables Altura y Temperatura. La variable Macho, no tiene gran aporte predictivo, por ello, fue descartado.

# Modelo de regresión lineal final

## Resumen del modelo

A continuación presentamos el modelo final:

$$Recuento=\beta_0+\beta_1*Temperatura+\beta_2*Altura+\epsilon_i$$

\changefontsizes{5pt}

```{r, echo = F, eval=T, message=F, warning= F, comment=""}
lm(Recuento~Temperatura+Altura,datos.train) -> modelo_final
summary(modelo_final)
```

## Análisis de variancia

```{r, echo = F, eval=T, message=F, warning= F, comment=""}
anova(modelo_final)
```

## Gráfico de dispersión 3D

```{r, echo = F, eval=T, message=F, comment="", warning= F, fig.align='center'}
library(scatterplot3d)
library(rgl)
library(car)
scatterplot3d(x = datos.train$Altura,y = datos.train$Temperatura, z = datos.train$Recuento, pch=16, highlight.3d=TRUE, xlab = "Altura", ylab = "Temperatura", zlab = "Recuento",angle = 80,
 type="h", main="3D Scatterplot")
```

```{r, echo = F, eval=T, message=F, comment="", warning= F, fig.align='center'}

lm(Recuento ~ Altura+Temperatura, data = datos.train) %>% avPlots
```

## Análisis de supuestos

### Valores predichos vs Residuos

```{r, echo = F, eval=T, message=F, comment="", warning= F, fig.align='center'}
modelo1 <- modelo_final
par(mfrow = c(1,1))
plot(modelo1,which = 1, pch = 16,    # optional parameters to make points blue
     col = '#006EA1')
```

### Gráfico de probabilidad normal de residuos

```{r, echo = F, eval=T, message=F, comment="", warning= F, fig.align='center'}
plot(modelo1,which = 2, pch = 16,    # optional parameters to make points blue
     col = '#006EA1')
```

### Valores predichos vs Raíz de los residuos estandarizados absolutos

```{r, echo = F, eval=T, message=F, comment="", warning= F, fig.align='center'}
plot(modelo1,which = 3, pch = 16,    # optional parameters to make points blue
     col = '#006EA1')
```

### Leverage vs Residuos estandarizados

```{r, echo = F, eval=T, message=F, comment="", warning= F, fig.align='center'}
plot(modelo1,which = 5, pch = 16,    # optional parameters to make points blue
     col = '#006EA1')
```

### Distancias de Cook

```{r, echo = F, eval=T, message=F, comment="", warning= F, fig.align='center'}
plot(modelo1,which = 4, pch = 16,    # optional parameters to make points blue
     col = '#006EA1')
```

### Distancias de Cook vs Leverage

```{r, echo = F, eval=T, message=F, comment="", warning= F, fig.align='center'}
plot(modelo1,which = 6, pch = 16,    # optional parameters to make points blue
     col = '#006EA1')
```

### Resumen de supuestos con check_model

```{r, echo = F, eval=T, message=F, comment="", warning= F, fig.align='center'}
modelo1 %>%
  performance::check_model()
```

### Prueba de hipótesis para la normalidad de residuos

#### Simetría de los residuos

\changefontsizes{7pt}

```{r, echo = F, eval=T, message=F, comment="", warning= F, fig.align='center'}
modelo1 %>%
  residuals() %>%
  moments::skewness()
```

#### Curtosis de los residuos

\changefontsizes{7pt}

```{r, echo = F, eval=T, message=F, comment="", warning= F, fig.align='center'}
modelo1 %>%
  residuals() %>%
  moments::kurtosis()
```

### Prueba de hipótesis para la normalidad de residuos

Las pruebas de hipótesis para normalidad de los residuos, con la siguiente hipótesis:

$H_0:$ Los residuos estandarizados del modelo planteado se distribuyen de forma similar a la función normal.

$H_1:$ Los residuos estandarizados del modelo planteado no se distribuyen de forma similar a la función normal.

\changefontsizes{7pt}

```{r, echo = F, eval=T, message=F, comment="", warning= F, fig.align='center'}
modelo1 %>%
  rstudent %>%
  stats::shapiro.test()
modelo1 %>%
  rstudent %>%
  nortest::ad.test()
modelo1 %>%
  rstudent %>%
  ks.test("pnorm")
```

### Prueba de hipótesis para la homocedasticidad

Por otro lado, al evaluar el supuesto de homocedasticidad y constrastar con la siguiente hipótesis:

$H_0:$ La variancia de los errores del modelo planteado es homocedástica.

$H_1:$ La variancia de los errores del modelo planteado es heterocedástica.

\changefontsizes{4pt}

```{r, echo = F, eval=T, message=F, comment="", warning= F, fig.align='center'}
modelo1 %>%
  ncvTest

library(olsrr)
modelo1 %>%
  ols_test_breusch_pagan

library(lmtest)
modelo1 %>%
  bptest
```

### Prueba de hipótesis para la autocorrelación de residuos

Al evaluar el supuesto de autocorrelación y constrastar la siguiente hipótesis:

$H_0:$ Los errores del modelo planteado no están autocorrelacionados.

$H_1:$ Los errores del modelo planteado están autocorrelacionados.

```{r, echo = F, eval=T, message=F, comment="", warning= F, fig.align='center'}
modelo1 %>% residuals() %>% TSA::acf()
```

```{r, echo = F, eval=T, message=F, comment="", warning= F, fig.align='center'}
modelo1 %>% residuals() -> residuales
plot(1:nrow(datos.train),residuales, type = "l")
```

```{r, echo = F, eval=T, message=F, comment="", warning= F, fig.align='center'}
modelo1 %>% dwtest(alternative = "two.sided")
```

\changefontsizes{7pt}

```{r, echo = F, eval=T, message=F, comment="", warning= F, fig.align='center'}
modelo1 %>% car::durbinWatsonTest(alternative = "two.sided",
                            max.lag=10,
                            reps=1e3)
```

### Leverages

\changefontsizes{4pt}

```{r, echo = F, eval=T, message=F, comment="", warning= F, fig.align='center'}

modelo1 %>% model.matrix -> X1
X1 %*% solve(t(X1)%*%X1) %*% t(X1) -> H1

round((modelo1 %>% hatvalues),4)

3 -> k1
length(datos.train$Recuento) -> n1

2*k1/n1

data.frame(leverage=diag(H1)>2*k1/n1,
 influencial=abs(modelo1 %>% rstudent)>2) %>%
  filter(influencial %in% "TRUE") %>%
  row.names()
```

Entonces, una observación podrá ser considerada como un leverage si $h_ii>2\frac{k}{n}$, donde $k$ es el número de coeficinetes de regresión y $n$ es el tamaño de la muetra, siempre y cuando $2\frac{k}{n}<1$

Para nuestro caso, tenemos que $k=3$ y nuestro $n=161$ observaciones entonces $2\frac{k}{n}<1$ = $2*(3/161)$ = $0.0373 < 1$

En nuestro caso vemos que se cumple para nuestro conjunto de datos donde tenemos que $2k<n$ -\> $n>2k$ -\> $n>2(p+1)$donde $p$ es el número de variables predictoras para nosotros $p=2$ por tanto vemos que se cumple la condición $161>2(2+1)>2$

Por otro lado, sabemos que no todo **leverage** es un punto influenciable.

Cuando se extrajo la matriz Hat para nuestras 161 obervaciones vemos que todos los valores son menores a uno.

Para nuestro caso son considerados valores leverage los siguientes: 26, 44, 77, 101, 125, 127 y 151. Sabemos que estas observaciones no son necesariamente influenciales pero se apartar de la distribución o el patron de los datos.

### Distancia de Cook

\changefontsizes{4pt}

```{r, echo = F, eval=T, message=F, comment="", warning= F, fig.align='center'}
round(modelo1 %>% cooks.distance(),4)

data.frame(cook=(modelo1 %>% cooks.distance()),
 influencial=modelo1 %>% cooks.distance %>% pf(3,161-3)>0.05) %>%
  filter(influencial %in% "TRUE") %>%
  row.names()

```

Por otro lado, se ha detectdo que ninguna de las observaciones poseen una distancia de cook estadísticamente significativa. Entonces, no existen observaciones que influyen en el cálculo de los betas en el modelo de regresión.

### COVRATIO

\changefontsizes{3pt}

```{r, echo = F, eval=T, message=F, comment="", warning= F, fig.align='center'}
modelo1 %>% covratio() 
3 -> k
length(datos.train$Recuento) -> n
n > 3*k

COVRATIO <- modelo1 %>% covratio() > 1+3*k/n | modelo1 %>% covratio() < 1-3*k/n
COVRATIO <- data.frame(id = seq(1:161), COVRATIO)
TRUES <- COVRATIO %>%
  filter(COVRATIO %in% "TRUE")
TRUES$id
```

Las observaciones con un alto COVRATIO fueron: 17, 26, 57, 100, 102 y 123. Estas observaciones influyen en el calculo de los estimadores del error estándar.

## Poder predictivo del modelo final

### MSE del modelo final sobre los datos de prueba

```{r, echo = F, eval=T, message=F, comment="", warning= F, fig.align='center'}
modelo_step %>% predict(newdata = data.frame(datos.test)) -> predicciones_test
(mean((predicciones_train - datos.train$Recuento)^2) -> test_mse)
```

### Indicadores predictivos con la base de datos de prueba

```{r, echo = F, eval=T, message=F, comment="", warning= F, fig.align='center'}
library(caret)
postResample(predicciones_test, obs = datos.test$Recuento)
```

bookdown::render_book()
bookdown::render_book("conteo-insectos")
bookdown::render_book("index.Rmd")
bookdown::render_book("index.Rmd")
bookdown::render_book("index.Rmd")
browseURL("docs/index.html")
bookdown::render_book("index.Rmd")
bookdown::render_book("index.Rmd")
bookdown::render_book("index.Rmd")
knitr::opts_chunk$set(echo = FALSE)
options(max.print = 9999,
scipen = 999)
datos <- readxl::read_xlsx("datos11.xlsx", sheet = "Sheet1")
datos$Macho <- factor(datos$Macho,
levels = c(0,1),
labels = c("Machos","Hembras"))
datos$Urbano <- factor(datos$Urbano,
levels = c(0,1),
labels = c("No","Sí"))
library(summarytools)
summarytools::descr(datos)
summary(datos)
library(dplyr)
datos %>%
select_if(is.numeric) %>%
pairs
library(psych)
datos %>%
select_if(is.numeric) %>%
pairs.panels
library(ggplot2)
library(GGally)
datos %>%
ggpairs + theme_bw()
library(ggplot2)
library(GGally)
datos %>%
ggpairs(upper = list(continuous = "density", combo = "box_no_facet"), lower = list(continuous = "points",
combo = "dot_no_facet")) + theme_bw()
#Generando gráfico de dispersión del número de bayas cosechables vs los Kg Cosechados por hectárea
library(ggplot2)
datos %>%
ggplot(aes(x=Altura,y=Recuento))+
geom_point(position = "jitter", size=3, colour="red")+
labs( title = "DIAGRAMA DE DISPERSIÓN",
subtitle = "Altura vs Recuento")+
geom_smooth(method = "lm")+
theme_test()
lm(Recuento~.,datos) -> modelo_completo
summary(modelo_completo)
anova(modelo_completo)
library(caret)
set.seed(6666)
train <- createDataPartition(y = datos$Recuento, p = 0.80, list = FALSE, times = 1)
datos.train <- datos[train, ]
datos.test  <- datos[-train, ]
# summarytools::descr(datos.train)
summary(datos.train)
# summarytools::descr(datos.test)
summary(datos.test)
par(mfrow = c(1,3))
hist(datos$Recuento,
main = "Datos completos",
sub = c("Media = 196.925"),
xlab = "Recuento")
hist(datos.train$Recuento,
main = "Datos de entrenamiento",
sub = c("Media = 196.7267"),
xlab = "Recuento")
hist(datos.test$Recuento,
main = "Datos de prueba",
sub = c("Media = 197.7436"),
xlab = "Recuento")
step(object = lm(formula = Recuento ~ 1, data = datos.train),
direction = "forward",
scope = formula(lm(Recuento~.,data=datos)),
trace = F) -> modelo_forward
modelo_forward %>% summary
AIC(modelo_forward)
library(tidyverse)
library(broom)
modelo_forward %>%
tidy %>%
filter(term != "(Intercept)") %>%
ggplot(aes(x = term, y = estimate)) +
geom_col() +
labs(title = "Coeficientes del modelo OLS") +
theme_bw() +
theme(axis.text.x = element_text(size = 8, angle = 90))
library(faraway)
modelo_forward %>% vif
modelo_forward %>% predict(newdata = data.frame(datos.train)) -> predicciones_train
(mean((predicciones_train - datos.train$Recuento)^2) -> training_mse)
library(caret)
postResample(predicciones_train, obs = datos.train$Recuento)
step(object = lm(formula = Recuento ~ ., data = datos.train),
direction = "backward",
scope = list(upper = ~., lower = ~1),
trace = F) -> modelo_backward
modelo_backward %>% summary
AIC(modelo_backward)
library(tidyverse)
library(broom)
modelo_backward %>%
tidy %>%
filter(term != "(Intercept)") %>%
ggplot(aes(x = term, y = estimate)) +
geom_col() +
labs(title = "Coeficientes del modelo OLS") +
theme_bw() +
theme(axis.text.x = element_text(size = 8, angle = 90))
library(faraway)
modelo_backward %>% vif
modelo_backward %>% predict(newdata = data.frame(datos.train)) -> predicciones_train
(mean((predicciones_train - datos.train$Recuento)^2) -> training_mse)
library(caret)
postResample(predicciones_train, obs = datos.train$Recuento)
step(object = lm(formula = Recuento ~ 1, data = datos.train),
direction = "both",
scope = formula(lm(Recuento~.,data=datos)),
trace = F,
k = log(nrow(datos.train))) -> modelo_step
modelo_step %>% summary
AIC(modelo_step)
library(tidyverse)
library(broom)
modelo_step %>%
tidy %>%
filter(term != "(Intercept)") %>%
ggplot(aes(x = term, y = estimate)) +
geom_col() +
labs(title = "Coeficientes del modelo OLS") +
theme_bw() +
theme(axis.text.x = element_text(size = 8, angle = 90))
library(faraway)
modelo_step %>% vif
modelo_step %>% predict(newdata = data.frame(datos.train)) -> predicciones_train
(mean((predicciones_train - datos.train$Recuento)^2) -> training_mse)
library(caret)
postResample(predicciones_train, obs = datos.train$Recuento)
lm(Recuento~Temperatura+Altura,datos.train) -> modelo_final
summary(modelo_final)
anova(modelo_final)
library(scatterplot3d)
library(rgl)
library(car)
scatterplot3d(x = datos.train$Altura,y = datos.train$Temperatura, z = datos.train$Recuento, pch=16, highlight.3d=TRUE, xlab = "Altura", ylab = "Temperatura", zlab = "Recuento",angle = 80,
type="h", main="3D Scatterplot")
lm(Recuento ~ Altura+Temperatura, data = datos.train) %>% avPlots
modelo1 <- modelo_final
par(mfrow = c(1,1))
plot(modelo1,which = 1)
plot(modelo1,which = 2)
plot(modelo1,which = 3)
plot(modelo1,which = 5)
plot(modelo1,which = 4)
plot(modelo1,which = 6)
modelo1 %>%
residuals() %>%
moments::skewness()
modelo1 %>%
residuals() %>%
moments::kurtosis()
modelo1 %>%
rstudent %>%
stats::shapiro.test()
modelo1 %>%
rstudent %>%
nortest::ad.test()
modelo1 %>%
rstudent %>%
ks.test("pnorm")
modelo1 %>%
ncvTest
library(olsrr)
modelo1 %>%
ols_test_breusch_pagan
library(lmtest)
modelo1 %>%
bptest
modelo1 %>% residuals() %>% TSA::acf()
modelo1 %>% residuals() -> residuales
plot(1:nrow(datos.train),residuales, type = "l")
modelo1 %>% dwtest(alternative = "two.sided")
modelo1 %>% car::durbinWatsonTest(alternative = "two.sided",
max.lag=10,
reps=1e3)
modelo1 %>% model.matrix -> X1
X1 %*% solve(t(X1)%*%X1) %*% t(X1) -> H1
round((modelo1 %>% hatvalues),4)
3 -> k1
length(datos.train$Recuento) -> n1
2*k1/n1
data.frame(leverage=diag(H1)>2*k1/n1,
influencial=abs(modelo1 %>% rstudent)>2) %>%
filter(influencial %in% "TRUE") %>%
row.names()
round(modelo1 %>% cooks.distance(),4)
data.frame(cook=(modelo1 %>% cooks.distance()),
influencial=modelo1 %>% cooks.distance %>% pf(3,161-3)>0.05) %>%
filter(influencial %in% "TRUE") %>%
row.names()
modelo1 %>% covratio()
3 -> k
length(datos.train$Recuento) -> n
n > 3*k
COVRATIO <- modelo1 %>% covratio() > 1+3*k/n | modelo1 %>% covratio() < 1-3*k/n
COVRATIO <- data.frame(id = seq(1:161), COVRATIO)
TRUES <- COVRATIO %>%
filter(COVRATIO %in% "TRUE")
TRUES$id
modelo_step %>% predict(newdata = data.frame(datos.test)) -> predicciones_test
(mean((predicciones_train - datos.train$Recuento)^2) -> test_mse)
library(caret)
postResample(predicciones_test, obs = datos.test$Recuento)
bookdown::render_book("index.Rmd")
bookdown::render_book("index.Rmd")
browseURL("docs/index.html")
bookdown::render_book("index.Rmd")
browseURL("docs/index.html")
bookdown::render_book("index.Rmd")
browseURL("docs/index.html")
bookdown::render_book("index.Rmd")
browseURL("docs/index.html")
bookdown::render_book("index.Rmd")
browseURL("docs/index.html")
bookdown::render_book("index.Rmd")
bookdown::render_book("index.Rmd")
browseURL("docs/index.html")
bookdown::render_book("index.Rmd")
bookdown::render_book("index.Rmd")
bookdown::render_book("index.Rmd")
knitr::opts_chunk$set(echo = FALSE)
options(max.print = 9999,
scipen = 999)
datos <- readxl::read_xlsx("datos11.xlsx", sheet = "Sheet1")
datos$Macho <- factor(datos$Macho,
levels = c(0,1),
labels = c("Machos","Hembras"))
datos$Urbano <- factor(datos$Urbano,
levels = c(0,1),
labels = c("No","Sí"))
library(summarytools)
summarytools::descr(datos)
summary(datos)
library(dplyr)
datos %>%
select_if(is.numeric) %>%
pairs
library(psych)
datos %>%
select_if(is.numeric) %>%
pairs.panels
library(ggplot2)
library(GGally)
datos %>%
ggpairs + theme_bw()
library(ggplot2)
library(GGally)
datos %>%
ggpairs(upper = list(continuous = "density", combo = "box_no_facet"), lower = list(continuous = "points",
combo = "dot_no_facet")) + theme_bw()
#Generando gráfico de dispersión del número de bayas cosechables vs los Kg Cosechados por hectárea
library(ggplot2)
datos %>%
ggplot(aes(x=Altura,y=Recuento))+
geom_point(position = "jitter", size=3, colour="red")+
labs( title = "DIAGRAMA DE DISPERSIÓN",
subtitle = "Altura vs Recuento")+
geom_smooth(method = "lm")+
theme_test()
lm(Recuento~.,datos) -> modelo_completo
summary(modelo_completo)
anova(modelo_completo)
library(caret)
set.seed(6666)
train <- createDataPartition(y = datos$Recuento, p = 0.80, list = FALSE, times = 1)
datos.train <- datos[train, ]
datos.test  <- datos[-train, ]
# summarytools::descr(datos.train)
summary(datos.train)
# summarytools::descr(datos.test)
summary(datos.test)
par(mfrow = c(1,3))
hist(datos$Recuento,
main = "Datos completos",
sub = c("Media = 196.925"),
xlab = "Recuento")
hist(datos.train$Recuento,
main = "Datos de entrenamiento",
sub = c("Media = 196.7267"),
xlab = "Recuento")
hist(datos.test$Recuento,
main = "Datos de prueba",
sub = c("Media = 197.7436"),
xlab = "Recuento")
step(object = lm(formula = Recuento ~ 1, data = datos.train),
direction = "forward",
scope = formula(lm(Recuento~.,data=datos)),
trace = F) -> modelo_forward
modelo_forward %>% summary
AIC(modelo_forward)
library(tidyverse)
library(broom)
modelo_forward %>%
tidy %>%
filter(term != "(Intercept)") %>%
ggplot(aes(x = term, y = estimate)) +
geom_col() +
labs(title = "Coeficientes del modelo OLS") +
theme_bw() +
theme(axis.text.x = element_text(size = 8, angle = 90))
library(faraway)
modelo_forward %>% vif
modelo_forward %>% predict(newdata = data.frame(datos.train)) -> predicciones_train
(mean((predicciones_train - datos.train$Recuento)^2) -> training_mse)
library(caret)
postResample(predicciones_train, obs = datos.train$Recuento)
step(object = lm(formula = Recuento ~ ., data = datos.train),
direction = "backward",
scope = list(upper = ~., lower = ~1),
trace = F) -> modelo_backward
modelo_backward %>% summary
AIC(modelo_backward)
library(tidyverse)
library(broom)
modelo_backward %>%
tidy %>%
filter(term != "(Intercept)") %>%
ggplot(aes(x = term, y = estimate)) +
geom_col() +
labs(title = "Coeficientes del modelo OLS") +
theme_bw() +
theme(axis.text.x = element_text(size = 8, angle = 90))
library(faraway)
modelo_backward %>% vif
modelo_backward %>% predict(newdata = data.frame(datos.train)) -> predicciones_train
(mean((predicciones_train - datos.train$Recuento)^2) -> training_mse)
library(caret)
postResample(predicciones_train, obs = datos.train$Recuento)
step(object = lm(formula = Recuento ~ 1, data = datos.train),
direction = "both",
scope = formula(lm(Recuento~.,data=datos)),
trace = F,
k = log(nrow(datos.train))) -> modelo_step
modelo_step %>% summary
AIC(modelo_step)
library(tidyverse)
library(broom)
modelo_step %>%
tidy %>%
filter(term != "(Intercept)") %>%
ggplot(aes(x = term, y = estimate)) +
geom_col() +
labs(title = "Coeficientes del modelo OLS") +
theme_bw() +
theme(axis.text.x = element_text(size = 8, angle = 90))
library(faraway)
modelo_step %>% vif
modelo_step %>% predict(newdata = data.frame(datos.train)) -> predicciones_train
(mean((predicciones_train - datos.train$Recuento)^2) -> training_mse)
library(caret)
postResample(predicciones_train, obs = datos.train$Recuento)
lm(Recuento~Temperatura+Altura,datos.train) -> modelo_final
summary(modelo_final)
anova(modelo_final)
library(scatterplot3d)
library(rgl)
library(car)
scatterplot3d(x = datos.train$Altura,y = datos.train$Temperatura, z = datos.train$Recuento, pch=16, highlight.3d=TRUE, xlab = "Altura", ylab = "Temperatura", zlab = "Recuento",angle = 80,
type="h", main="3D Scatterplot")
lm(Recuento ~ Altura+Temperatura, data = datos.train) %>% avPlots
modelo1 <- modelo_final
par(mfrow = c(1,1))
plot(modelo1,which = 1)
plot(modelo1,which = 2)
plot(modelo1,which = 3)
plot(modelo1,which = 5)
plot(modelo1,which = 4)
plot(modelo1,which = 6)
modelo1 %>%
residuals() %>%
moments::skewness()
modelo1 %>%
residuals() %>%
moments::kurtosis()
modelo1 %>%
rstudent %>%
stats::shapiro.test()
modelo1 %>%
rstudent %>%
nortest::ad.test()
modelo1 %>%
rstudent %>%
ks.test("pnorm")
modelo1 %>%
ncvTest
library(olsrr)
modelo1 %>%
ols_test_breusch_pagan
library(lmtest)
modelo1 %>%
bptest
modelo1 %>% residuals() %>% TSA::acf()
modelo1 %>% residuals() -> residuales
plot(1:nrow(datos.train),residuales, type = "l")
modelo1 %>% dwtest(alternative = "two.sided")
modelo1 %>% car::durbinWatsonTest(alternative = "two.sided",
max.lag=10,
reps=1e3)
modelo1 %>% model.matrix -> X1
X1 %*% solve(t(X1)%*%X1) %*% t(X1) -> H1
round((modelo1 %>% hatvalues),4)
3 -> k1
length(datos.train$Recuento) -> n1
2*k1/n1
data.frame(leverage=diag(H1)>2*k1/n1,
influencial=abs(modelo1 %>% rstudent)>2) %>%
filter(influencial %in% "TRUE") %>%
row.names()
round(modelo1 %>% cooks.distance(),4)
data.frame(cook=(modelo1 %>% cooks.distance()),
influencial=modelo1 %>% cooks.distance %>% pf(3,161-3)>0.05) %>%
filter(influencial %in% "TRUE") %>%
row.names()
modelo1 %>% covratio()
3 -> k
length(datos.train$Recuento) -> n
n > 3*k
COVRATIO <- modelo1 %>% covratio() > 1+3*k/n | modelo1 %>% covratio() < 1-3*k/n
COVRATIO <- data.frame(id = seq(1:161), COVRATIO)
TRUES <- COVRATIO %>%
filter(COVRATIO %in% "TRUE")
TRUES$id
modelo_step %>% predict(newdata = data.frame(datos.test)) -> predicciones_test
(mean((predicciones_train - datos.train$Recuento)^2) -> test_mse)
library(caret)
postResample(predicciones_test, obs = datos.test$Recuento)
performance::check_model(modelo_final)
modelo1 %>%
autoplot()
autoplot(modelo1)
autoplot(modelo_final)
ggplot2::autoplot(modelo_final)
modelo1 %>%
performance::check_model()
modelo1 %>%
performance::check_model()
modelo1 %>%
performance::check_model()
modelo1 %>%
performance::check_model()
modelo1 %>%
performance::check_model()
modelo1 %>%
performance::check_model()
modelo1 %>%
performance::check_model()
modelo1 %>%
performance::check_model()
modelo1 %>%
performance::check_model()
bookdown::render_book("index.Rmd")
modelo1 %>% residuals() %>% TSA::acf(pch = 16,    # optional parameters to make points blue
col = '#006EA1')
modelo1 %>% residuals() %>% TSA::acf()
modelo1 %>% residuals() -> residuales
plot(1:nrow(datos.train),residuales, type = "l", pch = 16,    # optional parameters to make points blue
col = '#006EA1')
modelo1 %>% forecast::checkresiduals(pch = 16,    # optional parameters to make points blue
col = '#006EA1')
modelo1 %>% forecast::checkresiduals(pch = 16,    # optional parameters to make points blue
col = '#006EA1')
bookdown::render_book("index.Rmd")
bookdown::render_book("index.Rmd")
